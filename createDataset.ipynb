{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fbd2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "from os import walk\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "facb08d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated, moving to folder no.  1\n",
      "Concatenated, moving to folder no.  2\n",
      "Concatenated, moving to folder no.  3\n",
      "Dataset training shape:  (95194, 32, 32, 1)\n",
      "Dataset testing shape:  (20400, 32, 32, 1)\n",
      "Dataset validation shape:  (20399, 32, 32, 1)\n",
      "Types training shape:  (95194, 1)\n",
      "Types testing shape:  (20400, 1)\n",
      "Types validation shape:  (20399, 1)\n"
     ]
    }
   ],
   "source": [
    "subfolders = [ f.path for f in os.scandir(\"Characters\\JPEGAugmented\\FinalData\") if f.is_dir() ]\n",
    "\n",
    "# Define the datasets here\n",
    "datasetTraining = np.ndarray(shape=(1, 32, 32, 1), dtype=np.uint8)\n",
    "datasetValidation = np.ndarray(shape=(1, 32, 32, 1), dtype=np.uint8)\n",
    "datasetTesting = np.ndarray(shape=(1, 32, 32, 1), dtype=np.uint8)\n",
    "typesTraining = np.ndarray(shape=(1, 1), dtype=np.uint8)\n",
    "typesTesting = np.ndarray(shape=(1, 1), dtype=np.uint8)\n",
    "typesValidation = np.ndarray(shape=(1, 1), dtype=np.uint8)\n",
    "\n",
    "# Define variables here\n",
    "counterTraining = 0\n",
    "counterTesting = 0\n",
    "chType = 0\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    \n",
    "    _, _, filenames = next(walk(subfolder))\n",
    "    \n",
    "    counter = 0\n",
    "    counterTraining = 0\n",
    "    counterTesting = 0\n",
    "    counterVal = 0\n",
    "    \n",
    "    training = int(len(filenames)*.7)\n",
    "    validation = int(len(filenames)*.15)\n",
    "    testing = len(filenames)-training-validation\n",
    "    \n",
    "    random.shuffle(filenames)\n",
    "    \n",
    "    # Define temp arrays here\n",
    "    tempDataTest = np.ndarray(shape=(testing, 32, 32, 1), dtype=np.uint8)\n",
    "    tempDataTrain = np.ndarray(shape=(training, 32, 32, 1), dtype=np.uint8)\n",
    "    tempDataVal = np.ndarray(shape=(validation, 32, 32, 1), dtype=np.uint8)\n",
    "    \n",
    "    tempTypesTest = np.ndarray(shape=(testing, 1), dtype=np.uint8)\n",
    "    tempTypesTrain = np.ndarray(shape=(training, 1), dtype=np.uint8)\n",
    "    tempTypesVal = np.ndarray(shape=(validation, 1), dtype=np.uint8)\n",
    "    \n",
    "    for filename in filenames:\n",
    "        image = Image.open(subfolder+\"\\\\\"+filename)\n",
    "        \n",
    "        x = img_to_array(image)\n",
    "        \n",
    "        if counter<training:\n",
    "            tempDataTrain[counterTraining] = x\n",
    "            tempTypesTrain[counterTraining] = chType\n",
    "            counterTraining += 1\n",
    "        elif counter<(training+validation):\n",
    "            tempDataVal[counterVal] = x\n",
    "            tempTypesVal[counterVal] = chType\n",
    "            counterVal += 1\n",
    "        else:\n",
    "            tempDataTest[counterTesting] = x\n",
    "            tempTypesTest[counterTesting] = chType\n",
    "            counterTesting += 1\n",
    "            \n",
    "        counter += 1\n",
    "    \n",
    "    datasetTraining = np.concatenate((datasetTraining,tempDataTrain), axis=0)\n",
    "    datasetTesting = np.concatenate((datasetTesting,tempDataTest), axis=0)\n",
    "    datasetValidation = np.concatenate((datasetValidation,tempDataVal), axis=0)\n",
    "    \n",
    "    typesTraining = np.concatenate((typesTraining,tempTypesTrain), axis = 0)\n",
    "    typesTesting = np.concatenate((typesTesting,tempTypesTest), axis=0)\n",
    "    typesValidation = np.concatenate((typesValidation,tempTypesVal), axis=0)\n",
    "    \n",
    "    chType += 1\n",
    "    print(\"Concatenated, moving to folder no. \", chType)\n",
    "\n",
    "print(\"Dataset training shape: \",datasetTraining.shape)\n",
    "print(\"Dataset testing shape: \",datasetTesting.shape)\n",
    "print(\"Dataset validation shape: \",datasetValidation.shape)\n",
    "print(\"Types training shape: \",typesTraining.shape)\n",
    "print(\"Types testing shape: \",typesTesting.shape)\n",
    "print(\"Types validation shape: \",typesValidation.shape)\n",
    "\n",
    "np.save(\"trainX.npy\",datasetTraining)\n",
    "np.save(\"trainY.npy\",typesTraining)\n",
    "np.save(\"testX.npy\", datasetTesting)\n",
    "np.save(\"testY.npy\", typesTesting)\n",
    "np.save(\"valX.npy\", datasetValidation)\n",
    "np.save(\"valY.npy\", typesValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d7f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20400, 1)\n"
     ]
    }
   ],
   "source": [
    "temp = np.load(\"testY.npy\")\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3167d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
